{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 2 column 1 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39;49mloads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 1 (char 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39m#interpret results of threading   \u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39mfor\u001b[39;00m i,val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(price_list):\n\u001b[0;32m---> 70\u001b[0m     result \u001b[39m=\u001b[39m val\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m     71\u001b[0m     \u001b[39m#print(result)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[39m#price_data = pd.DataFrame(result.json()['rows'])\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     myc_price \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([myc_price, result])\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn [21], line 48\u001b[0m, in \u001b[0;36mpull_myc_price\u001b[0;34m(start_unix_str, end_unix_str, page_size, page_no)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpull_myc_price\u001b[39m(start_unix_str, end_unix_str, page_size, page_no):\n\u001b[1;32m     47\u001b[0m     price_response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://dev.api.tracer.finance/trs/priceUpdates?from=\u001b[39m\u001b[39m{\u001b[39;00mstart_unix_str\u001b[39m}\u001b[39;00m\u001b[39m&to=\u001b[39m\u001b[39m{\u001b[39;00mend_unix_str\u001b[39m}\u001b[39;00m\u001b[39m&page=\u001b[39m\u001b[39m{\u001b[39;00mpage_no\u001b[39m}\u001b[39;00m\u001b[39m&pageSize=\u001b[39m\u001b[39m{\u001b[39;00mpage_size\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     price_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(price_response\u001b[39m.\u001b[39;49mjson()[\u001b[39m'\u001b[39m\u001b[39mrows\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m(price_data)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/requests/models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39mloads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[39m.\u001b[39mmsg, e\u001b[39m.\u001b[39mdoc, e\u001b[39m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 1 (char 1)"
     ]
    }
   ],
   "source": [
    "from autotrader import AutoData\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time \n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "#Download's price data and funding rate data for Mycelium Perp Swaps and Binance, has \n",
    "#about 45min run time.\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "'''Pulling Mycelium funding rate data to csv.'''\n",
    "#pull historical funding rate and price data\n",
    "myc_fr_response = requests.get(\"https://dev.api.tracer.finance/trs/fundingRates\")\n",
    "myc_fr_data = pd.DataFrame(myc_fr_response.json()['rows'])\n",
    "\n",
    "#write funding rate data to csv\n",
    "myc_fr_data.to_csv('raw_data/myc_fr.csv')\n",
    "\n",
    "print('1')\n",
    "#------------------------------------------------------------------------------------\n",
    "'''Calculate times for pulling rest of the mycelium price, binance perp funding rate and price data.'''\n",
    "\n",
    "#get first and last funding rate data times, used for mycelium price data\n",
    "start_unix_str = myc_fr_data['timestamp'].iloc[-1]\n",
    "end_unix_str = myc_fr_data['timestamp'].iloc[0]\n",
    "\n",
    "start_datetime = pd.to_datetime(start_unix_str, unit = 's').to_pydatetime()\n",
    "end_datetime = pd.to_datetime(end_unix_str, unit = 's').to_pydatetime()\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "'''Pulling mycelium price data to csv.'''\n",
    "\n",
    "#page size for price data\n",
    "page_size = 20000\n",
    "\n",
    "#get the number of data entries and first page of data\n",
    "price_response = requests.get(f'https://dev.api.tracer.finance/trs/priceUpdates?from={start_unix_str}&to={end_unix_str}&page=1&pageSize={page_size}')\n",
    "price_entries = price_response.json()['totalRecords'] # number of total price points recorded\n",
    "\n",
    "myc_price = pd.DataFrame(price_response.json()['rows'])\n",
    "print('2')\n",
    "#function used in threads to pull price data\n",
    "def pull_myc_price(start_unix_str, end_unix_str, page_size, page_no):\n",
    "    price_response = requests.get(f'https://dev.api.tracer.finance/trs/priceUpdates?from={start_unix_str}&to={end_unix_str}&page={page_no}&pageSize={page_size}')\n",
    "    price_data = pd.DataFrame(price_response.json()['rows'])\n",
    "    return(price_data)\n",
    "\n",
    "print('3')\n",
    "#create threads\n",
    "with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "    price_list=[]\n",
    "    for i in range(2, (price_entries//page_size)+2):\n",
    "        # submit job:\n",
    "        price_list.append(executor.submit(\n",
    "            pull_myc_price,\n",
    "            start_unix_str = start_unix_str,\n",
    "            end_unix_str = end_unix_str,\n",
    "            page_size = page_size,\n",
    "            page_no = i\n",
    "        ))\n",
    "        time.sleep(25)\n",
    "\n",
    "\n",
    "print('4')\n",
    "#interpret results of threading   \n",
    "for i,val in enumerate(price_list):\n",
    "    result = val.result()\n",
    "    #print(result)\n",
    "    #price_data = pd.DataFrame(result.json()['rows'])\n",
    "    myc_price = pd.concat([myc_price, result])\n",
    "    #print(i)\n",
    "\n",
    "print('5')\n",
    "#write price data to csv\n",
    "myc_price.to_csv('raw_data/myc_price.csv')\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "'''Pulling binance perp funding rate and price data to csv.'''\n",
    "'''\n",
    "#the following are the myc universe assets that have perps on binance, ETH = WETH, BTC = WBTC\n",
    "binance_universe = ['ETH','BTC','LINK','UNI','FXS','BAL','CRV']\n",
    "\n",
    "# perps on binance come with USDT or BUSD, so both will be used to compare\n",
    "perp_quote = ['USDT', 'BUSD']\n",
    "\n",
    "binance = AutoData(data_source ='ccxt', exchange = 'binanceusdm')\n",
    "for quote in perp_quote:\n",
    "    for ticker in binance_universe:\n",
    "        #pull data into data frames\n",
    "        try:\n",
    "            fr_data = binance._ccxt_funding_history(f'{ticker}{quote}', start_time=start_datetime, end_time=end_datetime)\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            price_data = binance.fetch(f'{ticker}{quote}', granularity='8h', start_time=start_datetime, end_time=end_datetime)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        #store data in csv's\n",
    "        fr_data.to_csv(f'raw_data/binance_fr/{ticker}{quote}.csv')\n",
    "        price_data.to_csv(f'raw_data/binance_price/{ticker}{quote}.csv')\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Future at 0x104e025f0 state=finished returned DataFrame>\n",
      "<Future at 0x1053c4940 state=finished returned DataFrame>\n",
      "<Future at 0x159a2c6a0 state=finished returned DataFrame>\n",
      "<Future at 0x1570f3970 state=finished returned DataFrame>\n",
      "<Future at 0x1570f2aa0 state=finished returned DataFrame>\n",
      "<Future at 0x1770eb310 state=finished returned DataFrame>\n",
      "<Future at 0x154d4a7a0 state=finished returned DataFrame>\n",
      "<Future at 0x154d4b220 state=finished returned DataFrame>\n",
      "<Future at 0x177440820 state=finished returned DataFrame>\n",
      "<Future at 0x177092bf0 state=finished returned DataFrame>\n",
      "<Future at 0x1770932e0 state=finished returned DataFrame>\n",
      "<Future at 0x159a1ffa0 state=finished returned DataFrame>\n",
      "<Future at 0x157320640 state=finished returned DataFrame>\n",
      "<Future at 0x1054be410 state=finished returned DataFrame>\n",
      "<Future at 0x1054bfdc0 state=finished returned DataFrame>\n",
      "<Future at 0x159ac7100 state=finished returned DataFrame>\n",
      "<Future at 0x159ac7e80 state=finished returned DataFrame>\n",
      "<Future at 0x159ac7640 state=finished returned DataFrame>\n",
      "<Future at 0x1776348b0 state=finished returned DataFrame>\n",
      "<Future at 0x177634280 state=finished returned DataFrame>\n",
      "<Future at 0x1776349a0 state=finished returned DataFrame>\n",
      "<Future at 0x1776379a0 state=finished returned DataFrame>\n",
      "<Future at 0x177634820 state=finished returned DataFrame>\n",
      "<Future at 0x1776353c0 state=finished returned DataFrame>\n",
      "<Future at 0x177634310 state=finished returned DataFrame>\n",
      "<Future at 0x177636ec0 state=finished returned DataFrame>\n",
      "<Future at 0x177634ca0 state=finished returned DataFrame>\n",
      "<Future at 0x1776359c0 state=finished returned DataFrame>\n",
      "<Future at 0x177634700 state=finished returned DataFrame>\n",
      "<Future at 0x1776342b0 state=finished returned DataFrame>\n",
      "<Future at 0x177635f00 state=finished returned DataFrame>\n",
      "<Future at 0x177634b80 state=finished returned DataFrame>\n",
      "<Future at 0x159ade980 state=finished returned DataFrame>\n",
      "<Future at 0x159adc6d0 state=finished returned DataFrame>\n",
      "<Future at 0x159adc4c0 state=finished returned DataFrame>\n",
      "<Future at 0x159adc130 state=finished returned DataFrame>\n",
      "<Future at 0x159adc190 state=finished raised JSONDecodeError>\n",
      "<Future at 0x159adc7f0 state=finished raised JSONDecodeError>\n",
      "<Future at 0x159adc490 state=finished raised JSONDecodeError>\n",
      "<Future at 0x159adead0 state=finished returned DataFrame>\n",
      "<Future at 0x159adeb00 state=finished returned DataFrame>\n",
      "<Future at 0x159adfc40 state=finished returned DataFrame>\n",
      "<Future at 0x159adfe20 state=finished returned DataFrame>\n",
      "<Future at 0x159ade2f0 state=finished returned DataFrame>\n",
      "<Future at 0x159adf070 state=finished returned DataFrame>\n",
      "<Future at 0x159adf7c0 state=finished returned DataFrame>\n",
      "<Future at 0x17ea58a90 state=finished returned DataFrame>\n",
      "<Future at 0x17ea58fa0 state=finished returned DataFrame>\n",
      "<Future at 0x159adf8e0 state=finished returned DataFrame>\n",
      "<Future at 0x159adef80 state=finished returned DataFrame>\n",
      "<Future at 0x159adce50 state=finished returned DataFrame>\n",
      "<Future at 0x159add360 state=finished returned DataFrame>\n",
      "<Future at 0x159ade3e0 state=finished returned DataFrame>\n",
      "<Future at 0x2cbf519f0 state=finished returned DataFrame>\n",
      "<Future at 0x2cbf51c60 state=finished returned DataFrame>\n",
      "<Future at 0x2cbf51e70 state=finished returned DataFrame>\n",
      "<Future at 0x1778146a0 state=finished returned DataFrame>\n",
      "<Future at 0x177814ac0 state=finished returned DataFrame>\n",
      "<Future at 0x1778148b0 state=finished returned DataFrame>\n",
      "<Future at 0x177814670 state=finished returned DataFrame>\n",
      "<Future at 0x177814730 state=finished returned DataFrame>\n",
      "<Future at 0x15505a5f0 state=finished returned DataFrame>\n",
      "<Future at 0x15505bfa0 state=finished returned DataFrame>\n",
      "<Future at 0x1550580d0 state=finished returned DataFrame>\n",
      "<Future at 0x155059ba0 state=finished returned DataFrame>\n",
      "<Future at 0x155059660 state=finished returned DataFrame>\n",
      "<Future at 0x15505bc70 state=finished returned DataFrame>\n",
      "<Future at 0x155058ac0 state=finished returned DataFrame>\n",
      "<Future at 0x155059a50 state=finished returned DataFrame>\n",
      "<Future at 0x155058b50 state=finished returned DataFrame>\n",
      "<Future at 0x155059930 state=finished returned DataFrame>\n",
      "<Future at 0x155059630 state=finished returned DataFrame>\n",
      "<Future at 0x15505bb80 state=finished returned DataFrame>\n",
      "<Future at 0x15505a200 state=finished returned DataFrame>\n",
      "<Future at 0x2c91aa740 state=finished returned DataFrame>\n",
      "<Future at 0x2c91ab250 state=finished returned DataFrame>\n",
      "<Future at 0x2c96ae740 state=finished returned DataFrame>\n",
      "<Future at 0x2c96af340 state=finished returned DataFrame>\n",
      "<Future at 0x2c91ab2e0 state=finished returned DataFrame>\n"
     ]
    }
   ],
   "source": [
    "for i,val in enumerate(price_list):\n",
    "    #result = val.result()\n",
    "    #print(result)\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 4000\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "#Clean's price data and funding rate data for Mycelium Perp Swaps to 8hr increments\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "''''Read Mycelium funding rate data from csv and put in formatable format'''\n",
    "#read raw data from csv\n",
    "myc_fr_raw = pd.read_csv('raw_data/myc_fr.csv', \n",
    "        usecols=['timestamp','symbol','endFundingRate','startFundingRate']\n",
    ") \n",
    "\n",
    "#define funding rate columns\n",
    "fr_symbols = myc_fr_raw.symbol\n",
    "fr_timestamp = pd.to_datetime(myc_fr_raw['timestamp'], unit = 's')\n",
    "fr = (myc_fr_raw.endFundingRate.astype(int) - myc_fr_data.startFundingRate.astype(int))/1000000\n",
    "\n",
    "#create Mycelium Funding rate data frame\n",
    "myc_fr = pd.DataFrame(\n",
    "        data = {'timestamp':fr_timestamp,\n",
    "                'symbol' : fr_symbols,\n",
    "                'funding_rate' :fr}).set_index('timestamp').iloc[::-1]\n",
    "\n",
    "#last date in records\n",
    "end = myc_fr.index[-1]\n",
    "\n",
    "#truncation start date for all data\n",
    "trunc_start = myc_fr.index[0]\n",
    "\n",
    "''''Read Mycelium price data from csv and put in formatable format'''\n",
    "\n",
    "#read raw data from csv \n",
    "myc_price_raw = pd.read_csv('raw_data/myc_price.csv',\n",
    "                            usecols=['timestamp', 'symbol','price'])\n",
    "\n",
    "#define funding rate columns\n",
    "price_symbol = myc_price_raw.symbol\n",
    "price_timestamp = pd.to_datetime(myc_price_raw['timestamp'], unit = 's')\n",
    "        #numbers 27 digits are too large to calculate in pd.Dataframe\n",
    "price = myc_price_raw['price'].str.removesuffix('000000000000000000000000000') # removes 27 zero's, divide 10^27\n",
    "price = price.astype({'price':'int'})/1000\n",
    "\n",
    "myc_price = pd.DataFrame(\n",
    "        data = {'timestamp':price_timestamp,\n",
    "                'symbol' : price_symbol,\n",
    "                'price' : price}).set_index('timestamp').iloc[::-1]\n",
    "\n",
    "\n",
    "'''Iterate through funding rate and price data filtering by token, reindexing to constant \n",
    "   frequecy datetime and populate missing data entries from reindexing'''\n",
    "\n",
    "#create list to store data frames for each token\n",
    "token_data = []\n",
    "#mycelium universe\n",
    "myc_universe = ['WETH','WBTC','LINK','UNI','USDC','USDT','DAI','FRAX','FXS','BAL','CRV']\n",
    "\n",
    "#define truncation start date\n",
    "for ticker in myc_universe:\n",
    "        #create dataframe for each ticker\n",
    "        fr_ = myc_fr[myc_fr.symbol == ticker]\n",
    "        price_ = myc_price[myc_price.symbol == ticker]\n",
    "\n",
    "        #set truncation start date\n",
    "        start_time = fr_.index[0]\n",
    "        if start_time > trunc_start:\n",
    "                trunc_start = start_time\n",
    "\n",
    "        #remove duplicates from the price data\n",
    "        price_ = price_[~price_.index.duplicated(keep='first')]\n",
    "\n",
    "        #create indexes for reindexing\n",
    "        hourly_index = pd.date_range(start= trunc_start, end= end, freq = 'h') # create index w/ const freq for comparison\n",
    "        sec_index = pd.date_range(start= trunc_start, end=end, freq = 's') # create index to fill entries at the top of each hour, e.g. \n",
    "                                                                                # need data at 8:00:00 to reindex back to h\n",
    "\n",
    "        #reindex data and populate timestamps with missings data\n",
    "        fr_data = fr_.reindex(index = hourly_index, method = 'ffill')\n",
    "        price_data = price_.reindex(index = sec_index, method = 'ffill')\n",
    "        price_data = price_data.reindex(index = hourly_index)\n",
    "\n",
    "        #create dataframe containing Funding Rate and price data for each token\n",
    "        data_ = pd.DataFrame(data = {'timestamp':hourly_index,\n",
    "                                     'funding_rate':fr_data['funding_rate'],\n",
    "                                     'price':price_data['price']})\n",
    "\n",
    "        data_dict = {'token': f'{ticker}',\n",
    "                    'myc_data': data_}\n",
    "\n",
    "        token_data.append(data_dict)\n",
    "\n",
    "\n",
    "\n",
    "#print(trunc_start)\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "### END OF PRODUCTION ###\n",
    "#------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664629200\n"
     ]
    }
   ],
   "source": [
    "print(start_unix_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2022-10-01 20:00:00', '2022-10-01 20:00:01',\n",
      "               '2022-10-01 20:00:02', '2022-10-01 20:00:03',\n",
      "               '2022-10-01 20:00:04', '2022-10-01 20:00:05',\n",
      "               '2022-10-01 20:00:06', '2022-10-01 20:00:07',\n",
      "               '2022-10-01 20:00:08', '2022-10-01 20:00:09',\n",
      "               ...\n",
      "               '2022-11-11 05:59:51', '2022-11-11 05:59:52',\n",
      "               '2022-11-11 05:59:53', '2022-11-11 05:59:54',\n",
      "               '2022-11-11 05:59:55', '2022-11-11 05:59:56',\n",
      "               '2022-11-11 05:59:57', '2022-11-11 05:59:58',\n",
      "               '2022-11-11 05:59:59', '2022-11-11 06:00:00'],\n",
      "              dtype='datetime64[ns]', length=3492001, freq='S')\n",
      "                    symbol  price\n",
      "timestamp                        \n",
      "2022-11-10 00:20:07    CRV  0.558\n",
      "2022-11-10 00:20:10    CRV  0.557\n",
      "2022-11-10 00:20:13    CRV  0.558\n",
      "2022-11-10 00:20:17    CRV  0.558\n",
      "2022-11-10 00:20:19    CRV  0.557\n",
      "...                    ...    ...\n",
      "2022-11-11 04:59:18    CRV  0.649\n",
      "2022-11-11 04:59:25    CRV  0.649\n",
      "2022-11-11 04:59:28    CRV  0.649\n",
      "2022-11-11 04:59:31    CRV  0.649\n",
      "2022-11-11 04:59:43    CRV  0.649\n",
      "\n",
      "[23598 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(price_index)\n",
    "print(price_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       symbol                                price   timestamp\n",
      "6        WBTC  17060500000000000000000000000000000  1668142783\n",
      "10       WBTC  17048500000000000000000000000000000  1668142771\n",
      "19       WBTC  17048500000000000000000000000000000  1668142768\n",
      "23       WBTC  17048500000000000000000000000000000  1668142765\n",
      "30       WBTC  17048500000000000000000000000000000  1668142758\n",
      "...       ...                                  ...         ...\n",
      "167071   WBTC  16011000000000000000000000000000000  1668039619\n",
      "167079   WBTC  16011000000000000000000000000000000  1668039617\n",
      "167084   WBTC  15994105000000000000000000000000000  1668039613\n",
      "167094   WBTC  15991270000000000000000000000000000  1668039610\n",
      "167099   WBTC  15991030000000000000000000000000000  1668039607\n",
      "\n",
      "[23853 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(myc_price_raw[myc_price_raw.symbol == 'WBTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from here down is either in construction or fucked\n",
    "\n",
    "#remove token addresses\n",
    "myc_fr_data = myc_fr_data.drop(['token'], axis =1)\n",
    "\n",
    "#define funding rate columns\n",
    "fr = (myc_fr_data.endFundingRate.astype(int) - myc_fr_data.startFundingRate.astype(int))/1000000\n",
    "\n",
    "time = pd.to_datetime(myc_fr_data['timestamp'], unit = 's')\n",
    "token = myc_fr_data.symbol\n",
    "\n",
    "myc_funding = pd.concat([time,token,fr], axis=1)\n",
    "myc_funding = myc_funding.rename(columns={0:'funding_rate'})\n",
    "\n",
    "##!!!!###\n",
    "token_data = []\n",
    "for ticker in myc_universe:\n",
    "        data = myc_fr[myc_fr.symbol == ticker]\n",
    "        data_dict = {\n",
    "                'token': f'{ticker}',\n",
    "                'data': data,\n",
    "        }\n",
    "        print(data)\n",
    "        token_data.append(data_dict)\n",
    "\n",
    "## new block ##\n",
    "import numpy as np\n",
    "page_size = 100\n",
    "price_response = requests.get(f'https://dev.api.tracer.finance/trs/priceUpdates?from={start_unix_str}&to={end_unix_str}&page=1&pageSize{page_size}')\n",
    "price_entries = price_response.json()['totalRecords']\n",
    "myc_price = pd.DataFrame(price_response.json()['rows'])\n",
    "\n",
    "for i in range(2,(price_entries//100)+2):\n",
    "    price_response = requests.get(f'https://dev.api.tracer.finance/trs/priceUpdates?from={start_unix_str}&to={end_unix_str}&page={i}&pageSize{page_size}')\n",
    "    price_data = pd.DataFrame(price_response.json()['rows'])\n",
    "    myc_price = pd.concat([myc_price, price_data])\n",
    "\n",
    "#remove headers that aren't required\n",
    "myc_price = myc_price.drop(['token','txnHash','blockNumber'], axis =1)\n",
    "\n",
    "#refactor prices to USD\n",
    "myc_price['price'] = myc_price['price'].str.removesuffix('000000000000000000000000000') # removes 27 zero's\n",
    "myc_price['price'] = myc_price['price'].astype({'price':'int'})/1000\n",
    "\n",
    "\n",
    "#Change UNIX time string objects to datetime objects\n",
    "myc_price['timestamp'] = pd.to_datetime(myc_price['timestamp'], unit = 's')\n",
    "myc_price.to_csv('myc_price_data/price_data.csv')\n",
    "\n",
    "print(len(myc_price.price))\n",
    "print(myc_price.to_markdown())\n",
    "\n",
    "### new block\n",
    "start_unix_str = myc_fr_data['timestamp'].iloc[-1]\n",
    "end_unix_str = myc_fr_data['timestamp'].iloc[0]\n",
    "\n",
    "start_unix = pd.to_datetime(end_unix_str, unit = 's').to_pydatetime()\n",
    "end_unix = pd.to_datetime(end_unix_str, unit = 's').to_pydatetime()\n",
    "\n",
    "print(start_unix)\n",
    "print(type(start_unix))\n",
    "\n",
    "### new block ###\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import json\n",
    "import requests\n",
    "\n",
    "page_size = 1000\n",
    "\n",
    "price_response = requests.get(f'https://dev.api.tracer.finance/trs/priceUpdates?from={start_unix_str}&to={end_unix_str}&page=1&pageSize{page_size}')\n",
    "price_entries = price_response.json()['totalRecords']\n",
    "myc_price = pd.DataFrame(price_response.json()['rows'])\n",
    "\n",
    "def pull_myc_price(start_unix_str, end_unix_str, page_size, page_no):\n",
    "    price_response = requests.get(f'https://dev.api.tracer.finance/trs/priceUpdates?from={start_unix_str}&to={end_unix_str}&page={page_no}&pageSize{page_size}')\n",
    "    price_data = pd.DataFrame(price_response.json()['rows'])\n",
    "    return(price_data)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "    price_list=[]\n",
    "    for i in range(2, (price_entries//page_size)+2):\n",
    "        # submit job:\n",
    "        price_list.append(executor.submit(\n",
    "            pull_myc_price,\n",
    "            start_unix_str = start_unix_str,\n",
    "            end_unix_str = end_unix_str,\n",
    "            page_size = page_size,\n",
    "            page_no = i\n",
    "        ))\n",
    "    \n",
    "for i,val in enumerate(price_list):\n",
    "    result = price_list[i].result()\n",
    "    myc_price = pd.concat([myc_price,result])\n",
    "\n",
    "myc_price.to_csv('raw_data/myc_price.csv')\n",
    "\n",
    "### new block ###\n",
    "fr_data = response.json()['rows']\n",
    "df_data = pd.DataFrame(fr_data)\n",
    "df_data = df_data.drop(['token','endFundingRate'], axis = 1)\n",
    "print(df_data.to_markdown())\n",
    "\n",
    "#for i in fr_data['rows']:\n",
    "#    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
